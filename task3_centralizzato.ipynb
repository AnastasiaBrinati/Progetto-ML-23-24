{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CD5Mx2QO76gXexswNlKAC_Lf5Bmw-Xzs",
      "authorship_tag": "ABX9TyPZC3IGZY/R/W4njij8IXX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiaBrinati/Progetto-ML-23-24/blob/main/task3_centralizzato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ciSSdWMW_J",
        "outputId": "6d444799-3474-40c2-e4d9-6f38648828ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializza il seed per NumPy per riproducibilità\n",
        "np.random.seed(42)\n",
        "\n",
        "# Inizializza il seed per TensorFlow per riproducibilità\n",
        "tf.random.set_seed(42)\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "# Reshape and scale the input features\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the target labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTrWXqjSlNHB",
        "outputId": "909588c2-eb1f-43d4-9d0e-27e9c8584c46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model builder function for hyperparameter tuning\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Tune the number of convolutional layers\n",
        "    for i in range(hp.Int('num_conv_layers', 1, 3)):\n",
        "        model.add(layers.Conv2D(\n",
        "            filters=hp.Int(f'filters_{i}', min_value=16, max_value=128, step=16),\n",
        "            kernel_size=hp.Choice(f'kernel_size_{i}', values=[3, 5]),\n",
        "            activation='relu',\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Tune the number of units and activation function for each Dense layer\n",
        "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),\n",
        "            activation=hp.Choice(f'activation_{i}', values=['PReLU','LeakyReLU','relu', 'tanh', 'sigmoid'])\n",
        "        ))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\", \"categorical_accuracy\", \"top_k_categorical_accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='mnist_tuning')\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model with the optimal hyperparameters\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_categorical_accuracy, test_top_k_categorical_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predictions on the validation set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "test_precision = precision_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "test_recall = recall_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "test_f1_score = f1_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "\n",
        "# Display metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Categorical Accuracy:\", test_categorical_accuracy)\n",
        "print(\"Test Top-K Categorical Accuracy:\", test_top_k_categorical_accuracy)\n",
        "print(\"Test Precision:\", test_precision)\n",
        "print(\"Test Recall:\", test_recall)\n",
        "print(\"Test F1 Score:\", test_f1_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH7b1XU-JnAV",
        "outputId": "26b7f526-95d7-4a47-8386-fe2f32300bce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 23m 13s]\n",
            "val_accuracy: 0.9601666927337646\n",
            "\n",
            "Best val_accuracy So Far: 0.9915000200271606\n",
            "Total elapsed time: 05h 32m 32s\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 0.0635 - accuracy: 0.9857 - categorical_accuracy: 0.9857 - top_k_categorical_accuracy: 0.9996\n",
            "313/313 [==============================] - 16s 51ms/step\n",
            "Test Loss: 0.06348137557506561\n",
            "Test Accuracy: 0.9857000112533569\n",
            "Test Categorical Accuracy: 0.9857000112533569\n",
            "Test Top-K Categorical Accuracy: 0.9995999932289124\n",
            "Test Precision: 0.9859502247152615\n",
            "Test Recall: 0.9857\n",
            "Test F1 Score: 0.985740145638161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZRJZgC7V_mtC"
      }
    }
  ]
}