{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CD5Mx2QO76gXexswNlKAC_Lf5Bmw-Xzs",
      "authorship_tag": "ABX9TyNR6Pf5CKX0qTKi/gfF4Voo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiaBrinati/Progetto-ML-23-24/blob/main/task3_centralizzato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Q7ciSSdWMW_J",
        "outputId": "119371f3-74ee-42c7-8cd1-2415612dca53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/129.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializza il seed per NumPy per riproducibilità\n",
        "np.random.seed(42)\n",
        "\n",
        "# Inizializza il seed per TensorFlow per riproducibilità\n",
        "tf.random.set_seed(42)\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "# Reshape and scale the input features\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the target labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "nTrWXqjSlNHB",
        "outputId": "b2df1f57-da4f-482f-8151-bfd5b46967cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model builder function for hyperparameter tuning\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Tune the number of convolutional layers\n",
        "    for i in range(hp.Int('num_conv_layers', 1, 3)):\n",
        "        model.add(layers.Conv2D(\n",
        "            filters=hp.Int(f'filters_{i}', min_value=16, max_value=128, step=16),\n",
        "            kernel_size=hp.Choice(f'kernel_size_{i}', values=[3, 5]),\n",
        "            activation='relu',\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Tune the number of units and activation function for each Dense layer\n",
        "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),\n",
        "            activation=hp.Choice(f'activation_{i}', values=['PReLU','LeakyReLU','relu', 'tanh', 'sigmoid'])\n",
        "        ))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\", \"categorical_accuracy\", \"top_k_categorical_accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='mnist_tuning')\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model with the optimal hyperparameters\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_categorical_accuracy, test_top_k_categorical_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predictions on the validation set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "test_precision = precision_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "test_recall = recall_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "test_f1_score = f1_score(np.argmax(y_test, axis=1), y_pred_classes, average='weighted')\n",
        "\n",
        "# Display metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Categorical Accuracy:\", test_categorical_accuracy)\n",
        "print(\"Test Top-K Categorical Accuracy:\", test_top_k_categorical_accuracy)\n",
        "print(\"Test Precision:\", test_precision)\n",
        "print(\"Test Recall:\", test_recall)\n",
        "print(\"Test F1 Score:\", test_f1_score)\n"
      ],
      "metadata": {
        "id": "MH7b1XU-JnAV",
        "outputId": "fbb28a99-419d-490b-fe1d-8b5100644082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 01m 24s]\n",
            "val_accuracy: 0.9698333144187927\n",
            "\n",
            "Best val_accuracy So Far: 0.9711666703224182\n",
            "Total elapsed time: 00h 10m 33s\n",
            "\n",
            "Search: Running Trial #4\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3                 |2                 |num_conv_layers\n",
            "64                |112               |filters_0\n",
            "5                 |3                 |kernel_size_0\n",
            "3                 |1                 |num_dense_layers\n",
            "32                |64                |units_0\n",
            "PReLU             |PReLU             |activation_0\n",
            "0.0001            |0.01              |learning_rate\n",
            "64                |16                |filters_1\n",
            "3                 |3                 |kernel_size_1\n",
            "128               |None              |filters_2\n",
            "3                 |None              |kernel_size_2\n",
            "80                |None              |units_1\n",
            "PReLU             |None              |activation_1\n",
            "32                |None              |units_2\n",
            "LeakyReLU         |None              |activation_2\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n",
            "1500/1500 [==============================] - 153s 100ms/step - loss: 0.4344 - accuracy: 0.8692 - categorical_accuracy: 0.8692 - top_k_categorical_accuracy: 0.9666 - val_loss: 0.1205 - val_accuracy: 0.9655 - val_categorical_accuracy: 0.9655 - val_top_k_categorical_accuracy: 0.9991\n",
            "Epoch 2/2\n",
            "1368/1500 [==========================>...] - ETA: 12s - loss: 0.1079 - accuracy: 0.9675 - categorical_accuracy: 0.9675 - top_k_categorical_accuracy: 0.9992"
          ]
        }
      ]
    }
  ]
}